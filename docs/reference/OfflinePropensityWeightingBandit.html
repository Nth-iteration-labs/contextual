<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Bandit: Offline Propensity Weighted Replay — OfflinePropensityWeightingBandit • contextual</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>


<!-- docsearch -->
<script src="../docsearch.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous" />
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>



<meta property="og:title" content="Bandit: Offline Propensity Weighted Replay — OfflinePropensityWeightingBandit" />
<meta property="og:description" content="Policy for the evaluation of policies with offline data through replay with propensity weighting." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">contextual</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.9.8.4</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/cmabs.html">Demo: Basic Synthetic cMAB Policies</a>
    </li>
    <li>
      <a href="../articles/cmabsoffline.html">Demo: Offline cMAB LinUCB evaluation</a>
    </li>
    <li>
      <a href="../articles/eckles_kaptein.html">Demo: MAB Replication Eckles &amp; Kaptein (Bootstrap Thompson Sampling)</a>
    </li>
    <li>
      <a href="../articles/epsilongreedy.html">Demo: Basic Epsilon Greedy</a>
    </li>
    <li>
      <a href="../articles/introduction.html">Getting started: running simulations</a>
    </li>
    <li>
      <a href="../articles/mabs.html">Demo: MAB Policies Comparison</a>
    </li>
    <li>
      <a href="../articles/ml10m.html">Demo: MovieLens 10M Dataset</a>
    </li>
    <li>
      <a href="../articles/offline_depaul_movies.html">Demo: Offline cMAB: CarsKit DePaul Movie Dataset</a>
    </li>
    <li>
      <a href="../articles/replication.html">Offline evaluation: Replication of Li et al 2010</a>
    </li>
    <li>
      <a href="../articles/simpsons.html">Demo: Bandits, Propensity Weighting &amp; Simpson's Paradox in R</a>
    </li>
    <li>
      <a href="../articles/sutton_barto.html">Demo: Replication Sutton &amp; Barto, Reinforcement Learning: An Introduction, Chapter 2</a>
    </li>
    <li>
      <a href="../articles/website_optimization.html">Demo: Replication of John Myles White, Bandit Algorithms for Website Optimization</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
<li>
  <a href="../articles/only_pkgdown/faq.html">FAQ</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/Nth-iteration-labs/contextual">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
      <form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
        </div>
      </form>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Bandit: Offline Propensity Weighted Replay</h1>
    <small class="dont-index">Source: <a href='https://github.com/Nth-iteration-labs/contextual/blob/master/R/bandit_offline_propensity_weighting.R'><code>R/bandit_offline_propensity_weighting.R</code></a></small>
    <div class="hidden name"><code>OfflinePropensityWeightingBandit.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Policy for the evaluation of policies with offline data through replay with propensity weighting.</p>
    </div>



    <h2 class="hasAnchor" id="usage"><a class="anchor" href="#usage"></a>Usage</h2>

    

<pre>
  <span class='no'>bandit</span> <span class='kw'>&amp;</span><span class='no'>lt</span>;- <span class='fu'>OfflinePropensityWeightingBandit</span>(<span class='no'>formula</span>,
                                             <span class='no'>data</span>, <span class='kw'>k</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>d</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
                                             <span class='kw'>unique</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>shared</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
                                             <span class='kw'>randomize</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>replacement</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
                                             <span class='kw'>jitter</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>arm_multiply</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
                                             <span class='kw'>inverted</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>

    


<dl'>
<dt><code>formula</code></dt><dd><p>formula (required). Format: <code>y.context ~ z.choice | x1.context + x2.xontext + ... | p.propensity </code>
When leaving out p.propensity, Doubly Robust Bandit uses marginal prob per arm for propensities:
By default,  adds an intercept to the context model. Exclude the intercept, by adding "0" or "-1" to
the list of contextual features, as in:
<code>y.context ~ z.choice | x1.context + x2.xontext -1 | p.propensity </code></p></dd>
<dt><code>data</code></dt><dd><p>data.table or data.frame; offline data source (required)</p></dd>
<dt><code>k</code></dt><dd><p>integer; number of arms (optional). Optionally used to reformat the formula defined x.context vector
as a <code>k x d</code> matrix. When making use of such matrix formatted contexts, you need to define custom
intercept(s) when and where needed in data.table or data.frame.</p></dd>
<dt><code>d</code></dt><dd><p>integer; number of contextual features (optional) Optionally used to reformat the formula defined
x.context vector as a <code>k x d</code> matrix. When making use of such matrix formatted contexts, you need
to define custom intercept(s) when and where needed in data.table or data.frame.</p></dd>
<dt><code>randomize</code></dt><dd><p>logical; randomize rows of data stream per simulation (optional, default: TRUE)</p></dd>
<dt><code>replacement</code></dt><dd><p>logical; sample with replacement (optional, default: TRUE)</p></dd>
<dt><code>jitter</code></dt><dd><p>logical; add jitter to contextual features (optional, default: TRUE)</p></dd>
<dt><code>arm_multiply</code></dt><dd><p>logical; multiply the horizon by the number of arms (optional, default: TRUE)</p></dd>
<dt><code>inverted</code></dt><dd><p>logical; have the propensity scores been weighted (optional, default: FALSE)</p></dd>
<dt><code>threshold</code></dt><dd><p>float (0,1); Lower threshold or Tau on propensity score values. Smaller Tau makes for less biased
estimates with more variance, and vice versa. For more information, see paper by Strehl at all (2010).
Values between 0.01 and 0.05 are known to work well.</p></dd>
<dt><code>drop_value</code></dt><dd><p>logical; Whether to drop a sample when the chosen arm does not equal the sampled arm. When TRUE,
the sample is dropped by setting the reward to null. When FALSE, the reward will be zero.</p></dd>
<dt><code>stabilized</code></dt><dd><p>logical; Whether to stabilize propensity weights.
One common issue with inverse propensity weighting g is that samples with
a propensity score very close to 0 will end up with an extremely large propensity weight,
potentially making the weighted estimator highly unstable.
A common alternative to the conventional weights are stabilized weights,
which use the marginal probability of treatment instead of 1 in the weight numerator.</p></dd>
<dt><code>unique</code></dt><dd><p>integer vector; index of disjoint features (optional)</p></dd>
<dt><code>shared</code></dt><dd><p>integer vector; index of shared features (optional)</p></dd>


</dl>

    <h2 class="hasAnchor" id="methods"><a class="anchor" href="#methods"></a>Methods</h2>

    


<dl'>

<dt><code>new(formula, data, k = NULL, d = NULL, unique = NULL, shared = NULL, randomize = TRUE,
                  replacement = TRUE, jitter = TRUE, arm_multiply = TRUE, inverted = FALSE)</code></dt><dd><p>generates and instantializes a new <code>OfflinePropensityWeightingBandit</code> instance.</p></dd>

<dt><code><a href='Bandit.html'>get_context(t)</a></code></dt><dd><p>argument:
<ul>
<li><p><code>t</code>: integer, time step <code>t</code>.</p></li>
</ul>
returns a named <code>list</code>
containing the current <code>d x k</code> dimensional matrix <code>context$X</code>,
the number of arms <code>context$k</code> and the number of features <code>context$d</code>.</p></dd>

<dt><code>get_reward(t, context, action)</code></dt><dd><p>arguments:
<ul>
<li><p><code>t</code>: integer, time step <code>t</code>.</p></li>
<li><p><code>context</code>: list, containing the current <code>context$X</code> (d x k context matrix),
<code>context$k</code> (number of arms) and <code>context$d</code> (number of context features)
(as set by <code>bandit</code>).</p></li>
<li><p><code>action</code>:  list, containing <code>action$choice</code> (as set by <code>policy</code>).</p></li>
</ul>
returns a named <code>list</code> containing <code>reward$reward</code> and, where computable,
<code>reward$optimal</code> (used by "oracle" policies and to calculate regret).</p></dd>

<dt><code><a href='Bandit.html'>post_initialization()</a></code></dt><dd><p>Randomize offline data by shuffling the offline data.table before the start of each
individual simulation when self$randomize is TRUE (default)</p></dd>

</dl>

    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Agarwal, Alekh, et al. "Taming the monster: A fast and simple algorithm for contextual bandits."
International Conference on Machine Learning. 2014.</p>
<p>Strehl, Alex, et al. "Learning from logged implicit exploration data." Advances in Neural Information
Processing Systems. 2010.</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>Core contextual classes: <code><a href='Bandit.html'>Bandit</a></code>, <code><a href='Policy.html'>Policy</a></code>, <code><a href='Simulator.html'>Simulator</a></code>,
<code><a href='Agent.html'>Agent</a></code>, <code><a href='History.html'>History</a></code>, <code><a href='Plot.html'>Plot</a></code></p>
<p>Bandit subclass examples: <code><a href='BasicBernoulliBandit.html'>BasicBernoulliBandit</a></code>, <code><a href='ContextualLogitBandit.html'>ContextualLogitBandit</a></code>,
<code>OfflinePropensityWeightingBandit</code></p>
<p>Policy subclass examples: <code><a href='EpsilonGreedyPolicy.html'>EpsilonGreedyPolicy</a></code>, <code><a href='ContextualLinTSPolicy.html'>ContextualLinTSPolicy</a></code></p></div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='kw'>if</span> (<span class='fl'>FALSE</span>) {

<span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>contextual</span>)
<span class='fu'>ibrary</span>(<span class='no'>data.table</span>)

<span class='co'># Import myocardial infection dataset</span>

<span class='no'>url</span>  <span class='kw'>&lt;-</span> <span class='st'>"http://d1ie9wlkzugsxr.cloudfront.net/data_propensity/myocardial_propensity.csv"</span>
<span class='no'>data</span>            <span class='kw'>&lt;-</span> <span class='fu'>fread</span>(<span class='no'>url</span>)

<span class='no'>simulations</span>     <span class='kw'>&lt;-</span> <span class='fl'>3000</span>
<span class='no'>horizon</span>         <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span>(<span class='no'>data</span>)

<span class='co'># arms always start at 1</span>
<span class='no'>data</span>$<span class='no'>trt</span>        <span class='kw'>&lt;-</span> <span class='no'>data</span>$<span class='no'>trt</span> + <span class='fl'>1</span>

<span class='co'># turn death into alive, making it a reward</span>
<span class='no'>data</span>$<span class='no'>alive</span>      <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>abs</a></span>(<span class='no'>data</span>$<span class='no'>death</span> - <span class='fl'>1</span>)

<span class='co'># calculate propensity weights</span>

<span class='no'>m</span>      <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/glm.html'>glm</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/AsIs.html'>I</a></span>(<span class='no'>trt</span>-<span class='fl'>1</span>) ~ <span class='no'>age</span> + <span class='no'>risk</span> + <span class='no'>severity</span>, <span class='kw'>data</span><span class='kw'>=</span><span class='no'>data</span>, <span class='kw'>family</span><span class='kw'>=</span><span class='fu'><a href='https://rdrr.io/r/stats/family.html'>binomial</a></span>(<span class='kw'>link</span><span class='kw'>=</span><span class='st'>"logit"</span>))
<span class='no'>data</span>$<span class='no'>p</span> <span class='kw'>&lt;-</span><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='no'>m</span>, <span class='kw'>type</span> <span class='kw'>=</span> <span class='st'>"response"</span>)

<span class='co'># run bandit - if you leave out p, Propensity Bandit uses marginal prob per arm for propensities:</span>
<span class='co'># table(private$z)/length(private$z)</span>

<span class='no'>f</span>          <span class='kw'>&lt;-</span> <span class='no'>alive</span> ~ <span class='no'>trt</span> <span class='kw'>|</span> <span class='no'>age</span> + <span class='no'>risk</span> + <span class='no'>severity</span> <span class='kw'>|</span> <span class='no'>p</span>

<span class='no'>bandit</span>     <span class='kw'>&lt;-</span> <span class='no'>OfflinePropensityWeightingBandit</span>$<span class='fu'>new</span>(<span class='kw'>formula</span> <span class='kw'>=</span> <span class='no'>f</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>data</span>)

<span class='co'># Define agents.</span>
<span class='no'>agents</span>      <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='no'>Agent</span>$<span class='fu'>new</span>(<span class='no'>LinUCBDisjointOptimizedPolicy</span>$<span class='fu'>new</span>(<span class='fl'>0.2</span>), <span class='no'>bandit</span>, <span class='st'>"LinUCB"</span>))

<span class='co'># Initialize the simulation.</span>

<span class='no'>simulation</span>  <span class='kw'>&lt;-</span> <span class='no'>Simulator</span>$<span class='fu'>new</span>(<span class='kw'>agents</span> <span class='kw'>=</span> <span class='no'>agents</span>, <span class='kw'>simulations</span> <span class='kw'>=</span> <span class='no'>simulations</span>, <span class='kw'>horizon</span> <span class='kw'>=</span> <span class='no'>horizon</span>)

<span class='co'># Run the simulation.</span>
<span class='no'>sim</span>  <span class='kw'>&lt;-</span> <span class='no'>simulation</span>$<span class='fu'><a href='Simulator.html'>run</a></span>()

<span class='co'># plot the results</span>
<span class='fu'><a href='https://rdrr.io/r/base/plot.html'>plot</a></span>(<span class='no'>sim</span>, <span class='kw'>type</span> <span class='kw'>=</span> <span class='st'>"cumulative"</span>, <span class='kw'>regret</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>, <span class='kw'>rate</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>legend_position</span> <span class='kw'>=</span> <span class='st'>"bottomright"</span>)

}</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Robin van Emden.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
   </div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script>
<script>
  docsearch({
    
    
    apiKey: '7d3ef95d72d5a68e705ce87f9919b959',
    indexName: 'nth_iteration_labs_contextual',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>



  </body>
</html>


