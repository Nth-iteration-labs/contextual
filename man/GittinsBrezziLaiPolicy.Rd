% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/policy_mab_gittins_bl.R
\name{GittinsBrezziLaiPolicy}
\alias{GittinsBrezziLaiPolicy}
\title{Policy: Gittins Approximation algorithm for choosing arms in a MAB problem.}
\description{
\code{GittinsBrezziLaiPolicy} Algorithm based on Brezzi and Lai (2002) "Optimal learning
and experimentation in bandit problems."
The algorithm provides an approximation of the Gittins index, by specifying
a closed-form expression, which is a function of the discount factor, and
the number of successes and failures associated with each arm.
}
\seealso{
Other contextual subclasses: \code{\link{BasicBandit}},
  \code{\link{ContextualBandit}},
  \code{\link{ContextualDisjointThompsonSamplingPolicy}},
  \code{\link{ContextualEpochGreedyDisjointPolicy}},
  \code{\link{ContextualEpsilonGreedyDisjointPolicy}},
  \code{\link{ContextualThompsonSamplingPolicy}},
  \code{\link{ContinuumBandit}},
  \code{\link{DoublyRobustOfflineBandit}},
  \code{\link{EpsilonFirstPolicy}},
  \code{\link{EpsilonGreedyPolicy}},
  \code{\link{Exp3Policy}},
  \code{\link{LiSamplingOfflineBandit}},
  \code{\link{LifPolicy}},
  \code{\link{LinUCBDisjointOptimizedPolicy}},
  \code{\link{LinUCBDisjointPolicy}},
  \code{\link{LinUCBHybridOptimizedPolicy}},
  \code{\link{LinUCBHybridPolicy}},
  \code{\link{OraclePolicy}}, \code{\link{RandomPolicy}},
  \code{\link{SoftmaxPolicy}},
  \code{\link{SyntheticBandit}},
  \code{\link{ThompsonSamplingPolicy}},
  \code{\link{UCB1Policy}}
}
